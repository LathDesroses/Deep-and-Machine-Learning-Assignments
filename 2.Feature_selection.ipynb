{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfde266b-ce27-457f-b9ac-79cd367e38a6",
   "metadata": {},
   "source": [
    "### Lath Essoh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c94ec5-4a35-4fd3-8c5d-a7d1fb382849",
   "metadata": {},
   "source": [
    "# 2.Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9224809-b32c-4c32-a6db-97cc8e6b5287",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "  \n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import math\n",
    "\n",
    "# Objective: forecast the insurance charges for each customer\n",
    "# The data contain some personal information for each individual\n",
    "\n",
    "# # Immport the dataset in the working environment\n",
    "dat = pd.read_csv('Insurance.csv')\n",
    "\n",
    "# Overview of variables\n",
    "dat.info()\n",
    "\n",
    "# Convert categorical variables to dummy variables\n",
    "dat = pd.get_dummies(dat, columns=['sex', 'smoker', 'region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48249de-170a-472f-b585-cdf633af7955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ********************************* Least Squares **********************************************\n",
    "\n",
    "# Increase the number of predictors by interacting the original features \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Increase the number of predictors by interacting the original features \n",
    "X = dat.drop(['charges'], axis = 1)\n",
    "interaction = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X = pd.DataFrame(interaction.fit_transform(X), columns=interaction.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33a535e-28d9-45d9-929f-04d8b3cd82b7",
   "metadata": {},
   "source": [
    "# *** QUESTION: How many features does input X contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f528f4cf-936a-47ee-97c0-f4f6d8f90301",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre de caractéristiques dans X est : 66\n"
     ]
    }
   ],
   "source": [
    "# Nombre de caractéristiques dans X\n",
    "nombre_de_caracteristiques = X.shape[1]\n",
    "print(f\"Le nombre de caractéristiques dans X est : {nombre_de_caracteristiques}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc2d3539-38d3-43cf-afdb-807da5de9619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (test): 4351.80\n"
     ]
    }
   ],
   "source": [
    "# Target\n",
    "y = dat['charges']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Check the performance of the model\n",
    "print('RMSE (test): %.2f' % math.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818fb0e-92da-4ef0-93f8-c52dc2ad19fb",
   "metadata": {},
   "source": [
    "# QUESTION: Why is it more convenient to use RMSE instead of MSE in this context? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb5eaa7-44fa-40de-a7d3-c5ba2aabf181",
   "metadata": {},
   "source": [
    "L'utilisation de la RMSE (Root Mean Squared Error) plutôt que de la MSE (Mean Squared Error) est généralement plus pratique dans le contexte de l'évaluation des performances des modèles de régression pour plusieurs raisons :\n",
    "\n",
    "Interprétation en Unités Réelles : La RMSE est exprimée dans les mêmes unités que la variable cible (dans ce cas, les charges d'assurance), ce qui facilite l'interprétation. Par exemple, si la RMSE est de 4351,80, cela signifie que, en moyenne, les prédictions du modèle s'écartent des valeurs réelles d'environ 4351,80 unités. En revanche, la MSE est exprimée en unités au carré, ce qui est moins intuitif.\n",
    "\n",
    "Échelle des Erreurs : La RMSE est plus sensible aux grandes erreurs que la MSE car elle prend la racine carrée de la moyenne des carrés des erreurs. Cela donne plus de poids aux grandes erreurs, ce qui peut être important pour les applications où les grandes erreurs sont particulièrement problématiques.\n",
    "\n",
    "Comparaison avec les Valeurs Observées : La RMSE permet de comparer directement la performance du modèle avec les valeurs observées. Par exemple, si l'on a des charges d'assurance typiques dans une certaine gamme, la RMSE donne une idée directe de l'écart moyen des prédictions par rapport à ces charges. La MSE, en revanche, donne un chiffre plus abstrait qui est moins directement comparable.\n",
    "\n",
    "Sensibilité aux Erreurs : Puisque la RMSE est dans la même unité que la variable cible, elle est souvent plus facilement compréhensible pour les parties prenantes non techniques qui peuvent ne pas être familières avec les concepts statistiques mais peuvent comprendre les écarts en unités réelles.\n",
    "\n",
    "En résumé, la RMSE est souvent préférée en raison de sa facilité d'interprétation et de sa capacité à fournir une mesure plus tangible de l'erreur moyenne des prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd5aac-e607-4dcf-8d45-3f208bc64c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ********************************** Best-subset selection *************************************\n",
    "# **********************************************************************************************\n",
    "\n",
    "# scikit-learn does not provide built-in functions for this method, but we can use some of its tools to implement it\n",
    "\n",
    "# Generate all possible feature subsets\n",
    "def best_subset_selection(X_train, y_train, X_test, y_test):\n",
    "    best_rmse_train = float('inf')\n",
    "    best_rmse_test = float('inf')\n",
    "    best_features = None\n",
    "    \n",
    "    features = X_train.columns\n",
    "    for i in range(1, len(features) + 1):\n",
    "        for subset in combinations(features, i):\n",
    "            rmse_train, rmse_test = evaluate_subset(subset, X_train, y_train, X_test, y_test)\n",
    "            if rmse_test < best_rmse_test:\n",
    "                best_rmse_train, best_rmse_test = rmse_train, rmse_test\n",
    "                best_features = subset\n",
    "    \n",
    "    return best_features, best_rmse_train, best_rmse_test\n",
    "\n",
    "# Define the function to calculate performance of a subset of features\n",
    "def evaluate_subset(features, X_train, y_train, X_test, y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train[list(features)], y_train)\n",
    "    y_pred_train = model.predict(X_train[list(features)])\n",
    "    y_pred_test = model.predict(X_test[list(features)])\n",
    "    return mean_squared_error(y_train, y_pred_train), mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Fit the models\n",
    "best_features, best_rmse_train, best_rmse_test = best_subset_selection(X_train, y_train, X_test, y_test)\n",
    "\n",
    "#...You can stop after a while because it will never converge!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68692425-1e93-463e-af99-955b1a5c6d86",
   "metadata": {},
   "source": [
    "# QUESTION: How many differnet models should the function estimate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10452205-0784-45ce-88ab-2c91e0f8941b",
   "metadata": {},
   "source": [
    "Pour déterminer combien de modèles différents la fonction `best_subset_selection` doit estimer, il est nécessaire de considérer le nombre de sous-ensembles de caractéristiques (features) que la fonction évalue. Puisque la fonction essaie toutes les combinaisons possibles des caractéristiques, le nombre total de modèles à estimer correspond au nombre de ces combinaisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "591c8bf1-4668-436c-acdd-6667cdca055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['bmi smoker_yes', 'age bmi', 'smoker_no', 'age', 'children', 'bmi region_northeast', 'sex_female region_northwest', 'age region_northeast', 'smoker_yes region_southeast', 'bmi sex_male', 'smoker_no region_southwest', 'age sex_female', 'bmi', 'age region_southwest', 'sex_female region_southwest']\n",
      "RMSE (test): 4239.30\n"
     ]
    }
   ],
   "source": [
    "# ********************************** Forward-stepwise selection **************************************\n",
    "\n",
    "# Define the function for forward stepwise selection\n",
    "def forward_stepwise_selection(X_train, y_train, X_test, y_test):\n",
    "    remaining_features = list(X_train.columns)\n",
    "    selected_features = []\n",
    "    best_rmse_test = float('inf')\n",
    "\n",
    "    while remaining_features:\n",
    "        best_feature = None\n",
    "        for feature in remaining_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            rmse_train, rmse_test = evaluate_features(current_features, X_train, y_train, X_test, y_test)\n",
    "            if rmse_test < best_rmse_test:\n",
    "                best_rmse_test = rmse_test\n",
    "                best_feature = feature\n",
    "        \n",
    "        if best_feature is None:\n",
    "            break\n",
    "        \n",
    "        selected_features.append(best_feature)\n",
    "        remaining_features.remove(best_feature)\n",
    "    \n",
    "    return selected_features, best_rmse_test\n",
    "\n",
    "# Define the function to evaluate the performance of the model with the given features\n",
    "def evaluate_features(features, X_train, y_train, X_test, y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train[features], y_train)\n",
    "    y_pred_train = model.predict(X_train[features])\n",
    "    y_pred_test = model.predict(X_test[features])\n",
    "    return mean_squared_error(y_train, y_pred_train), mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Fit the models\n",
    "selected_features, best_rmse_test = forward_stepwise_selection(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Check the selected features\n",
    "print('Selected features:', selected_features)\n",
    "\n",
    "# Check the performance of the model\n",
    "print('RMSE (test): %.2f' % math.sqrt(best_rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e50953c-6c0e-4986-8190-d633041085c7",
   "metadata": {},
   "source": [
    "# QUESTIONS: \n",
    "#      - Can you conclude that this model performs better than least-squares regression?\n",
    "#      - Does this model have a higher or lower bias than the least squares regression?\n",
    "#      - Do you expect to find the same set of features if you used backward-stepwise selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c05f4c-12f8-499e-9458-79165ef0a71a",
   "metadata": {},
   "source": [
    "### QUESTIONS\n",
    "\n",
    "#### 1. Can you conclude that this model performs better than least-squares regression?\n",
    "\n",
    "Oui, en se basant sur la comparaison des valeurs de la RMSE, on peut conclure que le modèle de sélection avant pas à pas (forward stepwise selection) est plus performant que le modèle de régression des moindres carrés. La RMSE pour le modèle de sélection avant pas à pas est de 4239,30, ce qui est inférieur à la RMSE de 4351,80 du modèle de régression des moindres carrés. Une RMSE plus faible signifie que les prédictions du modèle sont en moyenne plus proches des valeurs réelles.\n",
    "\n",
    "#### 2. Does this model have a higher or lower bias than the least squares regression?\n",
    "\n",
    "Ce modèle a probablement un biais plus élevé par rapport à la régression des moindres carrés. La sélection avant pas à pas ajoute les caractéristiques de manière incrémentale, ce qui peut simplifier le modèle en incluant seulement un sous-ensemble des caractéristiques. Cela peut introduire un biais plus élevé, tout en réduisant la variance. En revanche, le modèle de régression des moindres carrés utilise toutes les caractéristiques disponibles, ce qui entraîne un biais plus faible, mais une variance plus élevée. Comme le modèle de sélection avant pas à pas peut ne pas inclure toutes les caractéristiques, il est possible qu'il sous-ajuste légèrement les données, ce qui augmente le biais.\n",
    "\n",
    "\n",
    "#### 3. Do you expect to find the same set of features if you used backward-stepwise selection?\n",
    "\n",
    "Non, on ne s'attend pas à obtenir le même ensemble de caractéristiques avec la sélection arrière pas à pas. Les méthodes de sélection avant et arrière pas à pas conduisent souvent à des ensembles de caractéristiques différents car elles procèdent de manière opposée :\n",
    "\n",
    "La sélection avant pas à pas commence avec aucune caractéristique et ajoute les plus significatives à chaque étape.\n",
    "La sélection arrière pas à pas commence avec toutes les caractéristiques et retire les moins significatives à chaque étape.\n",
    "Étant donné que ces méthodes suivent des chemins opposés, elles peuvent prioriser des caractéristiques différentes au cours du processus de sélection, ce qui conduit à des ensembles finaux de caractéristiques distincts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
